---
title: "w241: Experiments and Causality"
subtitle: "Blocking and Clustering"
author: "David Reiley, David Broockman, D. Alex Hughes"
institute: "UC Berkeley, School of Information"
date: "Updated: `r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts] 
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, echo=FALSE, message=FALSE, include=FALSE}
library(tidyverse)
library(ggplot2)
library(patchwork)
library(data.table)

library(magrittr)

library(lmtest)
library(sandwich)

options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = TRUE, dpi = 300)


theme_set(theme_minimal())

set.seed(1)
```

# Blocking

- Hard to know if it was due to chance when there are large differences between treatment and control.
- Need to reduce the size of the differences that can arise by chance.
- Increase statistical power given an experiment with same sample and effect size.
- If some variables are related to the outcome, restrict ourselves to randomizations that keep treatment and control similar.

---

```{r, echo=FALSE}
## Note that in this code, until we note otherwise are are not doing 
## randomization inference to measure uncertainty. Instead, these simulations 
## are designed to simulate what effect you might generate when you *actually*
## conduct your experiment. 
```

---

# Make Data

```{r define functions, echo = FALSE} 
make_data <- function(effect_size=0) {
  group <- c(rep("Man",20),rep("Woman",20))

  po_control <- c(
    seq(from = 1, to = 20), 
    seq(from = 51, to = 70)
    )

  ## Suppose there is no effect. 
  ## Then, the potential outcomes to control are equal 
  ## to the potential outcomes to treatment. 

  po_treatment <- po_control + effect_size

  d <- data.table(
    'Control'   = po_control,
    'Treatment' = po_treatment, 
    'group'     = group
  )
}

randomize <- function(size=40) { 
  ## an (unnecessary) function to randomize units into 
  ## treatment and control 
  ## ---
  ## args: 
  ##  - units_per_group: how many zero and one should be returned
  
  assignment_vector <- rep(c('Control', 'Treatment'), each = size / 2)
  sample(assignment_vector)
} 
```

```{r}
d <- make_data(effect_size=0)
head(d)
```

---
# Randomization

```{r}
d[ , assignment := randomize(size=40)][ , 
  table('Sex' = group, 'Assignment' = assignment)]

d[ , assignment := randomize(size=40)][ , 
  table('Sex' = group, 'Assignment' = assignment)]
```

---
# Block Randomization

```{r} 
block_randomize <- function(size) { 
  ## this function will be executed /within/ the  data.table that 
  ## holds the data. It could be run outside, but the assignment 
  ## in place that data.table provides make it clean inside.
  conditions <- c('Control', 'Treatment')
  
  if(size %% 2 == 0) { 
    ## if there are an even number of units in each block this is easy
    urn <- rep(conditions, times = size/2)  
  } else if(size %% 2 == 1) { 
    ## if there are an odd number, then produce conditions to the 
    ## nearest even number that is less than the number of units 
    ## then add one more assignment condition, sampled at random
    urn <- c(rep(conditions, times = (size/2) - 0.5), sample(conditions, size = 1))
  } 
  
  ## now, shuffle it up return the shuffled sequence
  assignment <- sample(urn)
  return(assignment)
}
```

---
# Randomization

```{r run randomize}
d[ , block_assignment := block_randomize(size=.N), by = group][ , 
  table('Sex' = group, 'Assignment' = block_assignment)]

d[ , block_assignment := block_randomize(size=.N), by = group][ , 
  table('Sex' = group, 'Assignment' = block_assignment)]
```

---
# Conduct Experiment 

```{r}
conduct_experiment <- function(potential_control, potential_treatment, assignment) { 
  outcomes <- potential_treatment * I(assignment == "Treatment") + 
    potential_control * I(assignment == "Control")
  
  return(outcomes)
}

d[ , Y := conduct_experiment(Control, Treatment, block_assignment)]

head(d)
```

---
# Estimate ATE

```{r}
estimate_ate <- function(y_values, treatment, verbose=FALSE) { 
  
  treatment_group_mean <- mean(y_values[treatment == 'Treatment'])
  control_group_mean   <- mean(y_values[treatment == 'Control'])
  
  ate <- treatment_group_mean - control_group_mean
  
  if(verbose) {
    return(
      list(
        "tg_mean" = treatment_group_mean, 
        "cg_mean" = control_group_mean, 
        "ate" = ate))
    } else { 
      return("ate" = ate)
      }
}

ate <- d[ , estimate_ate(y_values = Y, treatment = block_assignment, verbose=TRUE)]
ate
```

---
# Simulate A Normal Study

```{r}
simulate_normal_study <- function(effect_size) { 
  ## create world 
  d <- make_data(effect_size=effect_size)

  ## randomly assign and count the number of women in treatment 
  d[ , assignment := randomize()]
  
  women_in_treatment <- d[group == 'Woman' & assignment == 'Treatment', .N]
  
  ## measure outcomes 
  d[ , Y := conduct_experiment(Control, Treatment, assignment)]
  
  ## estimate ate 
  ate <- d[ , estimate_ate(y_values = Y, treatment = assignment)]
  
  ## return objects 
  ##  - `ate` from the `estimate_ate` function.
  ##  - `women_in_treatment` as a count
  return(list('ate' = ate, 'women_in_treatment' = women_in_treatment))
}
```

---
# Run One Normal Study

```{r run a single normal study]}
normal_study <- simulate_normal_study(effect_size = 0)
normal_study
```

---
# Simulate Many Normal Studies 

```{r}
many_normal_studies <- replicate(
  n = 1000, 
  expr = simulate_normal_study(effect_size = 10))

many_normal_studies <- t(many_normal_studies)
head(many_normal_studies)
```

```{r make normal study plots, echo = FALSE} 
normal_ate_density <- ggplot() + 
  aes(x = unlist(many_normal_studies[,1])) + 
  geom_density(fill = '#003262', alpha = 0.7) + 
  scale_x_continuous(limits = c(-30, 30)) + 
  geom_vline(xintercept = 10, color = 'darkorange') + 
  labs(
    title = 'Zero Effect, Simple Randomization', 
    subtitle = 'Some extreme effects',
    x = 'Estimated ATE', 
    y = 'Density'
  )

normal_ate_by_women <- ggplot() + 
  aes(x = unlist(many_normal_studies[,1]), y = unlist(many_normal_studies[,2])) + 
  geom_jitter() + 
  geom_vline(xintercept = 10, color = 'darkorange') + 
  scale_x_continuous(limits = c(-30, 30)) + 
  scale_y_continuous(limits = c(4, 16)) + 
  labs(
    title = 'Treatment Effect vs. Women in Treatment', 
    subtitle = 'Linear, increasing relationship', 
    x = 'Estimated ATE', 
    y = 'Women in Treatment'
  )
```

---
# Plot Normal ATE 

```{r, message = FALSE, echo = FALSE, dev='svglite', fig.height=4, fig.align='center'}
normal_ate_density | normal_ate_by_women 
```

--- 

class: inverse, center, middle

# Benefits of Blocking

---
# Simulate a Block Randomized Study 

```{r}
simulate_blocked_study <- function(effect_size) { 
  ## create world 
  d <- make_data(effect_size=effect_size)
  
  ## randomly assign and count the number of women in treatment 
  d[ , assignment := block_randomize(20), by = group]

  women_in_treatment <- d[group == 'Woman' & assignment == 'Treatment', .N]
  
  ## measure outcomes 
  d[ , Y := conduct_experiment(Control, Treatment, assignment)]
  
  ## estimate ate 
  ate <- d[ , estimate_ate(y_values = Y, treatment = assignment)]
  
  ## return objects 
  ##  - `ate` from the `estimate_ate` function.
  ##  - `women_in_treatment` as a count 
  return(list('ate' = ate, 'women_in_treatment' = women_in_treatment))
}
```

---
# Simulate a Block Randomized Study 
```{r}
blocked_study <- simulate_blocked_study(effect_size = 10)
blocked_study
```

---
# Simulate Many Block Randomized Studies 

```{r}
many_blocked_studies <- replicate(
  n = 1000, 
  expr = simulate_blocked_study(effect_size = 10)
)

many_blocked_studies <- t(many_blocked_studies)
head(many_blocked_studies)
```

```{r, echo = FALSE}
blocked_ate_density <- ggplot() + 
  aes(x = unlist(many_blocked_studies[,1])) + 
  geom_density(fill = 'darkred', alpha = 0.7) + 
  geom_vline(xintercept = 10, color = 'darkorange') + 
  scale_x_continuous(limits = c(-30, 30)) + 
  labs(
    title = 'Zero Effect, Blocked Randomization', 
    subtitle = 'Results tightly centered at true treatment effect',
    x = 'Estimated ATE', y = 'Density'
  )

blocked_ate_by_women <- ggplot() + 
  aes(x = unlist(many_blocked_studies[,1]), y = unlist(many_blocked_studies[,2])) + 
  geom_jitter() + 
  geom_vline(xintercept = 10, color = 'darkorange') + 
  scale_x_continuous(limits = c(-30, 30)) + 
  scale_y_continuous(limits = c(4, 16)) + 
  labs(
    title = 'Treatment Effect vs. Women in Treatment', 
    subtitle = '', 
    x = 'Estimated ATE', 
    y = 'Women in Treatment'
  )
```

---
# Plot Blocked and Unblocked ATE

```{r, echo = FALSE}
## Notice that even though the true effect is 10: 
## - When we pursue a simple randomization there are a large number of
##   
```


```{r, message=FALSE, warning=FALSE, echo=FALSE, dev='svglite', fig.height=4, fig.align='center'}
(normal_ate_density | normal_ate_by_women) /
(blocked_ate_density | blocked_ate_by_women)
```

---

# P-values of Blocked vs. Normal Study 

- Blocking allows for more precision (efficiency) by not conducting randomization where covariates (e.g. sex) are very imbalanced
- This means that your estimator will produce an estimate that is closer to the *true* causal effect
- This is an estimate that is closer to the orange lines on the last slide

---

# Preview: Regression 

```{r}
d <- make_data(effect_size = 10)
d[ , assignment := randomize()]
d[ , Y := conduct_experiment(Control, Treatment, assignment)]

model_simple <- d[ , lm(Y ~ assignment)]
model_mf     <- d[ , lm(Y ~ assignment + group)]
```

---

# Preview: Regression, Cont'd 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
## assuming classical standard errors are appropriate (for ease of presentation)
stargazer::stargazer(
  model_simple, model_mf, 
  type = 'text', 
  omit.stat = c('ser', 'F'), 
  report = 'vcsp*', 
  ci = TRUE, 
  covariate.labels = c('Assigned Treatment', 'Group: Woman', 'Intercept'), 
  column.labels = c('Unblocked', 'Blocked')
)
```

---

# Summary of Blocking

## Blocking

- Reduces the probability that a large Treatment vs. Control difference can occur by change by balancing the presence of similar units across Treatment and Control
- Can dramatically reduce the **standard error** of the estimator (i.e. the standard deviation of the sampling distribution)
- Is successful if the blocks predict the outcome
- Is unsuccessful if the blocks do **not** predict the outcome

## Power 
- Is affected by (a) sample size; and, (b) ratio of treatment effect to uncertainty about the estimate of treatment effect
- The standard deviation of the outcome is often much smaller within groups that are measurable before conducting the experiment

---

class: inverse, center, middle

# Clustering 

---

# Overview of Clustering 

## Clustering

- Often, units can be observed individually, but must be assigned to the same condition
- If there is covariance between group membership and outcomes (often there is) then this experiment does not do *as good a job* at breaking the relationship between treatment assignment and potential outcomes
- Alternatively, you might think of this experiment as producing less *information* about the treatment effect relative to the background noise of the world

---

# Examples of Clustering 

## School Length
- Cannot randomly assign *at the student level* the length of the school day
- Instead, every student at the same school (or district, or state) has to receive the same length

## Broadcast TV Advertisements 
- In broadcast TV, it is not possible to assign advertisements (e.g. for [Babbitt's Sports](https://youtu.be/uguewe3uvo4)) to specific individuals
- Instead, whole markets receive the same ads

## Retail Stores and Prices 
- [Retail stores](https://frontierruckus.bandcamp.com/album/deadmalls-and-nightfalls-2) cannot individually assign price discounts to shoppers
- However, prices can be manipulated at the store-level and purchases observed at the individual-level

---

# Reading Assignment 

- Please read *Field Experiments* pages 80-85. 

---

class: inverse, center, middle 

# Clustering Example 

---

# Setting up Data 

## Cluster: The level where treatment is assigned 
- Notice that outcomes can be observed at more fine-grained levels
- There may be difference in *cluster-average* outcomes: 
  - A teacher stubs their toe on the way to school 
  - It is hot or cold in one classroom


```{r}
classrooms_number <- 8
students_number   <- 16 # this is MIDS, not kindergarten

classroom_ids_vector <- rep(x = 1:8, each = 16)
classroom_ids_vector
```

---

# Classroom Example 

```{r}
classroom_noise_vector <- 1:8 + rnorm(n=8, mean=0, sd=.5)
```

```{r make the data table}
potential_outcomes_data <- data.table(
  student_id      = 1:(8*16), 
  classroom_id    = classroom_ids_vector, 
  classroom_noise = rep(classroom_noise_vector, each = students_number)
)

setkey(potential_outcomes_data, 'classroom_id')

potential_outcomes_data[ , 
  student_outcomes_control := rnorm(n=.N, mean=10) + classroom_noise]
potential_outcomes_data[ , 
  student_outcomes_treat := student_outcomes_control + rnorm(n=.N, mean=1.5)]
```

---

# Classroom Example, cont'd 

```{r cluster assignment}
urn <- rep(c('Control', 'Treatment'), each = classrooms_number/2)

cluster_assignment_table <- data.table(
  classroom_id         = potential_outcomes_data[ , unique(classroom_id)],
  classroom_assignment = sample(urn),
  key = 'classroom_id'
)

experiment_data <- merge(
  x = potential_outcomes_data, 
  y = cluster_assignment_table, 
  on = 'classroom_id')
```

---

# Classroom Example, cont'd 

```{r}
head(experiment_data)
```

---

# Classroom Example, cont'd 

```{r}
experiment_data[ , classroom_assignment == 'Treatment']
```

---

# Classroom Example, cont'd 

```{r}
experiment_data[ , Y := conduct_experiment(
  potential_control   = student_outcomes_control, 
  potential_treatment = student_outcomes_treat, 
  assignment          = classroom_assignment )
  ]

cluster_ate <- experiment_data[ , estimate_ate(
  y_values  = Y,
  treatment =  classroom_assignment, 
  verbose   = TRUE)
  ]

cluster_ate
```

---

# Notice $\rho$ between classroom and $Y$

```{r, echo = FALSE, dev='svglite', fig.height=4, fig.align='center'} 
experiment_data %>% 
  ggplot() + 
  aes(
    x = student_id, 
    y = Y, 
    color = as.factor(classroom_id), 
    shape = classroom_assignment) + 
  geom_point() + 
  labs(
    shape = 'Treatment Assignment', 
    color = 'Classroom', 
    x     = 'Student ID', 
    y     = 'Outcome',
    title = 'Cluster Assignment')
```

---

# Classroom Example, Sharp Null

## Repeat the reassignment process
- **Under the sharp null hypothesis** we assume that the potential outcomes to treatment that we *observe* for the units in the treatment group, $Y_{i}(1)|d_{i}=1$, are equal to the potential outcomes to control that we *do not observe* for the units in the treatment group, $Y_{i}(0)|d_{i}=1$. 
- Similarly, **under the sharp null hypothesis** we assume that the potential outcomes to control that we *observe* for the people who are in the control group, $Y_{i}(0)|d_{i}=0$ are equal to the potential outcomes to treatment that we *do not observe* for the units in the control group, $Y_{i}(1)|d_{i}=0$

## Take care
- Take care to notice how this statement of the sharp null hypothesis is different from the guarantees of apples-to-apples comparisons that are achieved through randomization

---

# Classroom Example, Cluster RI Function

```{r, echo = FALSE}
## This is the first time in this code that we're running a *proper* 
## randomization inference loop. 
## Notice, that the data is flowing from: 
##  - `potential_outcomes` data --> 
##  - `experiment_data` --> 
##  - `cluster_ri_ates`
## 
## We get to actually *observe* one set of outcomes -- the realized potential outcomes
## And from this set of realized potential outcomes we then conduct our randomization 
##   inference. 
```


```{r define cluster ri function}
cluster_ri <- function(x_data, clustered) { 
  if(clustered == TRUE) { 
    urn <- rep(c('Control', 'Treatment'), each = x_data[ , length(unique(classroom_id))/2])
    cluster_assignment_table <- data.table(
             classroom_id            = x_data[ , unique(classroom_id)],
             ri_classroom_assignment = sample(urn),
           key = 'classroom_id'
    )
  
    d <- merge(x_data, cluster_assignment_table, on = 'classroom_id')
    d[ , .(group_mean = mean(Y)), 
       keyby = .(ri_classroom_assignment) 
       ][ , diff(group_mean)]    
  } else if(clustered == FALSE) {
    d <- x_data
    d[ , .(group_mean = mean(Y)),
       keyby = .(sample(classroom_assignment))
       ][ , diff(group_mean)]
  }
}
```

---

# Classroom Example, Cluster RI Function

```{r run cluster ri function once}
cluster_ri(x_data = experiment_data, clustered = TRUE)
```

---

# Classroom Example, Conduct Cluster RI 

```{r}
cluster_ri_ates <- replicate(
  n = 5000, 
  cluster_ri(x_data = experiment_data, clustered = TRUE)
)
```

---

# Classroom Example, Plot Cluster RI

```{r, echo = FALSE, dev='svglite', fig.height=4, fig.align='center'} 
ggplot() + 
  geom_density(aes(x = cluster_ri_ates), fill = '#003262', alpha = .5) + 
  geom_vline(xintercept = cluster_ate[['ate']], color = 'darkorange') + 
  labs(
    x = 'Randomization Inference ATEs (in blue)',
    title = 'Cluster RI and estimated Treatment Effect',
    subtitle = sprintf('Two-sided p-value: %.2f', mean(abs(cluster_ri_ates) >= cluster_ate[['ate']]))
  )
```

---

class: inverse, center, middle

# Perils of Ignoring Clustering

---

# What if we ignore clustering? 

## What if we analyze results as though there wasn't clustering? 

- Randomization happened at the classroom level, but our analysis ignores it? 
- **Result**: p-values will be *too small* and false rejection rate will be larger than $\alpha$ that you're controlling for
- Potentially *much* larger depending on the correlation between classrooms and outcomes. 


    cluster_ri <- function(x_data, clustered) { 
      if(clustered == TRUE) { 
        ## ... we're going to use the second clause of 
        ## `cluster_ri`, where we flag clustered==FALSE
      } else if(clustered == FALSE) {
        d <- x_data
        d[ , .(group_mean = mean(Y)),
           keyby = .(sample(classroom_assignment))
           ][ , diff(group_mean)]
      }
    }

---

# What if we ignore clustering? 

- In the `clustered == FALSE` clause, randomization is handled by simply sampling the vector called `classroom_assignment`. 
- Notice the individual-level randomization

```{r}
experiment_data[ , sample(classroom_assignment)][1:40]
```


```{r}
non_clustered_ates <- replicate(
  n = 5000, 
  cluster_ri(x_data = experiment_data, clustered = FALSE)
)
```

---

# Recall: Two-sample t-test

(Note: It isn't necessary to remember this formula from previous classes.) 

$$t = \frac{\overline{X}_{1} - \overline{X}_{2}}{\sqrt{\frac{s^{2}_{1}}{N_{1}} + \frac{s^{2}_{2}}{N_{2}}}}$$

---

# What if we ignore clustering? (cont'd)

```{r, echo = FALSE, dev='svglite', fig.height=4, fig.align='center'} 
ggplot() + 
  geom_density(aes(x = cluster_ri_ates),    fill = '#003262', alpha = 0.5) + 
  geom_density(aes(x = non_clustered_ates), fill = '#FDB515', alpha = 0.5) + 
  geom_vline(xintercept = cluster_ate[['ate']], color = 'darkorange') + 
  labs(
    x = 'Correct cluster RI ATEs in blue; incorrect RI ATEs in gold',
    title = 'Cluster RI and estimated Treatment Effect',
    subtitle = sprintf(
      'Correct Two-sided p-value: %.2f; incorrect two-sided p-value: %.2f', 
      mean(abs(cluster_ri_ates) >= abs(cluster_ate[['ate']])), 
      mean(abs(non_clustered_ates) >= abs(cluster_ate[['ate']]))
      )
  )
```

---

# Summary 

- When units are assigned to treatment or control in clusters, larger differences between `Treatment` and `Control` outcomes will happen by chance 
- To account for this uncertainty, when conducting randomization inference, *match the experiment's assignment process*
  - If assignment happened at random, randomization inference needs to as well
  - If assignment happened with clusters, randomization inference needs to as well
  - If assignment happened with blocks, randomization inference needs to as well
- Stats software (e.g. `vcovCL` in R) can estimate correct clustered $SEs$ in a regression framework 

---

# Summary

## Power is relatively worse when

- Average between cluster differences are larger 
- Within cluster differences are smaller 
- The number of clusters is small

## Power is relatively better when

- Average between cluster differences are smaller 
- Within cluster differences are larger 
- The number of clusters is large 